from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
import os
from dotenv import load_dotenv
import openai

# === Cargar variables de entorno ===
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    raise RuntimeError("Falta la variable de entorno OPENAI_API_KEY")

QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

if not QDRANT_URL or not QDRANT_API_KEY:
    raise RuntimeError("Faltan variables de entorno QDRANT_URL o QDRANT_API_KEY")

# === Inicializar FastAPI ===
app = FastAPI(title="Chatbot Legal")

# === Inicializar servicios ===
model_embeddings = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# === Patrones para identificar colecciones ===
PATRONES = {
    "COIP": {
        "keywords": ["coip", "c√≥digo org√°nico integral penal", "delitos", "penas", "homicidio", "robo", "estafa"],
        "especialidad": "Derecho Penal",
        "descripcion": "C√≥digo Org√°nico Integral Penal",
    },
    "C√≥digo de Comercio": {
        "keywords": ["c√≥digo de comercio", "mercantil", "empresa", "comerciante", "sociedad an√≥nima", "contrato mercantil"],
        "especialidad": "Derecho Mercantil",
        "descripcion": "C√≥digo de Comercio",
    },
    "C√≥digo de la Ni√±ez": {
        "keywords": ["c√≥digo de la ni√±ez", "ni√±os", "adolescentes", "menores", "patria potestad", "tutela"],
        "especialidad": "Derecho de Familia y Ni√±ez",
        "descripcion": "C√≥digo de la Ni√±ez y Adolescencia",
    },
    "C√≥digo Civil": {
        "keywords": ["c√≥digo civil", "derecho civil", "personas", "bienes", "obligaciones", "contratos civiles"],
        "especialidad": "Derecho Civil",
        "descripcion": "C√≥digo Civil",
    },
    "Constituci√≥n": {
        "keywords": ["constituci√≥n", "derechos fundamentales", "garant√≠as constitucionales", "estado", "poderes p√∫blicos"],
        "especialidad": "Derecho Constitucional",
        "descripcion": "Constituci√≥n",
    }
}

# === Modelo de entrada ===
class ConsultaChat(BaseModel):
    pregunta: str

# === Funci√≥n para detectar colecci√≥n y datos ===
def detectar_coleccion_y_datos(pregunta: str):
    pregunta_lower = pregunta.lower()
    for coleccion, datos in PATRONES.items():
        if any(keyword in pregunta_lower for keyword in datos["keywords"]):
            return coleccion, {
                "tipo": coleccion,
                "especialidad": datos["especialidad"],
                "descripcion": datos["descripcion"]
            }
    return None, {
        "tipo": "Desconocido",
        "especialidad": "Derecho General",
        "descripcion": "documento legal no identificado"
    }

# === Construcci√≥n del prompt ===
def construir_prompt(contexto: str, pregunta: str, tipo_documento: dict, tiene_contexto_relevante: bool = True) -> str:
    from datetime import datetime
    fecha_hora = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    if tiene_contexto_relevante:
        especialidad = tipo_documento.get('especialidad', 'Derecho General')
        descripcion = tipo_documento.get('descripcion', 'documento legal')
        tipo = tipo_documento.get('tipo', 'Documento Legal')
        
        return f"""Act√∫as como un JUEZ especializado en {especialidad} ecuatoriano.

INSTRUCCIONES OBLIGATORIAS:
Debes estructurar tu respuesta como una SENTENCIA JUDICIAL con el siguiente formato:

üìÖ FECHA Y HORA:
{fecha_hora}

‚öñÔ∏è RAZ√ìN DE LA SENTENCIA:
[An√°lisis jur√≠dico detallado basado en el {tipo} proporcionado. Cita art√≠culos espec√≠ficos y fundamentos legales aplicables al caso presentado]

üèõÔ∏è VEREDICTO:
[CULPABLE/INOCENTE - con justificaci√≥n legal espec√≠fica basada en los art√≠culos del {tipo}]

üè¢ LUGAR DE RECLUSI√ìN:
[Si es culpable: especificar centro penitenciario seg√∫n gravedad del delito]
[Si es inocente: "Libertad inmediata del procesado"]

üìã CONCLUSI√ìN:
[Resumen de la sentencia, penas aplicables, derechos del procesado y disposiciones finales]

NOTIF√çQUESE Y C√öMPLASE.

CONTEXTO LEGAL ({tipo}):
{contexto}

CASO A JUZGAR:
{pregunta}

IMPORTANTE: Basa tu sentencia √öNICAMENTE en el {tipo} proporcionado. Cita art√≠culos espec√≠ficos."""
    else:
        return f"""Act√∫as como un JUEZ especializado en legislaci√≥n ecuatoriana.

‚ö†Ô∏è IMPORTANTE: La informaci√≥n espec√≠fica sobre este caso NO se encuentra en el documento legal proporcionado.

Estructura tu respuesta como sentencia, pero indicando la limitaci√≥n:

üìÖ FECHA Y HORA:
{fecha_hora}

‚öñÔ∏è RAZ√ìN DE LA SENTENCIA:
No se cuenta con el marco legal espec√≠fico en el documento proporcionado para este caso. Sin embargo, bas√°ndome en principios generales del derecho ecuatoriano:

üèõÔ∏è VEREDICTO:
SUSPENDIDO - Falta de marco legal espec√≠fico en el documento proporcionado

üè¢ LUGAR DE RECLUSI√ìN:
No aplicable hasta contar con legislaci√≥n espec√≠fica

üìã CONCLUSI√ìN:
Esta sentencia provisional se basa en conocimiento general jur√≠dico y NO en el documento espec√≠fico proporcionado.
Se requiere consultar la legislaci√≥n correspondiente y asesoramiento legal especializado.

CASO PRESENTADO:
{pregunta}

‚ö†Ô∏è ADVERTENCIA JUDICIAL: Sentencia no definitiva por falta de marco legal espec√≠fico."""

# === Endpoint principal ===
@app.post("/chat", summary="Consulta al chatbot con contexto jur√≠dico")
async def consultar_chat(req: ConsultaChat):
    try:
        coleccion, tipo_documento = detectar_coleccion_y_datos(req.pregunta)

        if coleccion is None:
            prompt = construir_prompt("", req.pregunta, tipo_documento, tiene_contexto_relevante=False)
        else:
            vector_pregunta = model_embeddings.encode([req.pregunta])[0]

            resultados = qdrant_client.search(
                collection_name=coleccion,
                query_vector=vector_pregunta,
                limit=4
            )

            if not resultados:
                prompt = construir_prompt("", req.pregunta, tipo_documento, tiene_contexto_relevante=False)
            else:
                contexto = "\n\n".join([r.payload.get("text", "") for r in resultados])
                prompt = construir_prompt(contexto, req.pregunta, tipo_documento)

        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # Puedes cambiar a "gpt-4o" si tienes acceso
            messages=[
                {"role": "system", "content": "Eres un asistente legal que responde con base en el contexto legal proporcionado."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        texto_respuesta = response.choices[0].message.content.strip()

        return {"respuesta": texto_respuesta}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error al generar la respuesta: {str(e)}")
